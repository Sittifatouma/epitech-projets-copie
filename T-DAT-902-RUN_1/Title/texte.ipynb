{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le bon \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# text recognition\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Télécharger les stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Chemin vers le dossier contenant les images\n",
    "dossier_images = r\"/Users/dimitriraymond/Documents/Epitech/Semestre 2/DAT/data/Movie_Poster_Dataset\"\n",
    "\n",
    "\n",
    "# configurations\n",
    "config = ('-l eng --oem 1 --psm 3')\n",
    "\n",
    "text = pytesseract.image_to_string(img, config=config)\n",
    "\n",
    "# Liste pour stocker les résultats\n",
    "resultats = []\n",
    "\n",
    "# Parcourir les fichiers et dossiers dans le dossier d'images\n",
    "for dossier, sous_dossiers, fichiers in os.walk(dossier_images):\n",
    "    for fichier in fichiers:\n",
    "        # Vérifier si le fichier est une image JPG\n",
    "        if fichier.endswith(\".jpg\") or fichier.endswith(\".jpeg\"):\n",
    "            chemin_image = os.path.join(dossier, fichier)\n",
    "\n",
    "            # Lire l'image\n",
    "            img = cv2.imread(chemin_image)\n",
    "\n",
    "            # Reconnaissance de texte\n",
    "            text = pytesseract.image_to_string(img, config=config)\n",
    "\n",
    "            # Convertir le texte en minuscules\n",
    "            text_lower = text.lower()\n",
    "\n",
    "            # Tokenisation des mots\n",
    "            tokens = word_tokenize(text_lower)\n",
    "\n",
    "            # Supprimer les mots vides (stop words)\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "            # Identifier les parties du discours des mots\n",
    "            pos_tags = nltk.pos_tag(filtered_tokens)\n",
    "\n",
    "            # Extraire les noms (substantifs) et les prénoms (proper nouns)\n",
    "            nouns = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
    "            proper_nouns = [word for word, pos in pos_tags if pos.startswith('NNP')]\n",
    "\n",
    "            # Calculer la fréquence des mots\n",
    "            word_freq = FreqDist(filtered_tokens)\n",
    "            most_common_words = word_freq.most_common(10)\n",
    "\n",
    "            # Identifier les synonymes des mots les plus fréquents\n",
    "            synonyms = []\n",
    "            for word, freq in most_common_words:\n",
    "                synsets = wordnet.synsets(word)\n",
    "                if synsets:\n",
    "                    syn = synsets[0].lemmas()[0].name()\n",
    "                    synonyms.append(syn)\n",
    "\n",
    "            # Ajouter le titre de l'image et les résultats à la liste des résultats\n",
    "            titre_image = fichier  # Utiliser le nom du fichier comme titre\n",
    "            resultats.append([titre_image, nouns, proper_nouns, synonyms])\n",
    "\n",
    "# Écrire les résultats dans un fichier CSV\n",
    "chemin_fichier_csv = r\"/Users/dimitriraymond/Documents/Epitech/Semestre 2/DAT/resultc/fichier5.csv\"\n",
    "with open(chemin_fichier_csv, mode='w', newline='') as fichier_csv:\n",
    "    writer = csv.writer(fichier_csv)\n",
    "    writer.writerow([\"Titre de l'image\", \"Sujets\", \"Nom\", \"Synonymes\"])  # Écrire l'en-tête du fichier CSV\n",
    "    writer.writerows(resultats)  # Écrire les résultats\n",
    "\n",
    "print(\"Terminé. Les résultats ont été enregistrés dans\", chemin_fichier_csv)\n",
    "\n",
    "\n",
    "\n",
    "# Imprimer les résultats\n",
    "#print(\"Sujets du texte (noms) :\", nouns)\n",
    "#print(\"Prénoms du texte :\", proper_nouns)\n",
    "#print(\"Mots les plus fréquents :\", most_common_words)\n",
    "#print(\"Synonymes des mots les plus fréquents :\", synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"/Users/dimitriraymond/Documents/Epitech/Semestre 2/DAT/resultc/fichier6.csv\")\n",
    "\n",
    "df['Synonymes'] = df['Synonymes'].str.strip(\"[]\").str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "df = pd.concat([df, df['Synonymes'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df = df.drop('Nom', axis=1)\n",
    "\n",
    "df = df.drop('Synonymes', axis=1)\n",
    "\n",
    "df\n",
    "\n",
    "df.to_csv(r\"/Users/dimitriraymond/Documents/Epitech/Semestre 2/DAT/resultc/nouveau_fichier.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
